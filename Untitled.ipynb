{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Layer, self).__init__()\n",
    "        self.layer = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10)\n",
    "layer = Layer(10, 1)\n",
    "y = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4770], grad_fn=<ReluBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.share_memory_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4770], grad_fn=<ReluBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.requires_grad_=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1010])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1010])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4770], grad_fn=<ReluBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ReluBackward at 0x7f7119fd2cc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.randn(5, requires_grad=True)\n",
    "t = torch.randn(5, requires_grad=True)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(o,t)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2164, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-15ce08a89098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "loss.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.randn(10)\n",
    "layer_1 = Layer(10, 1)\n",
    "y_1 = layer_1(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0243], grad_fn=<ReluBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ReluBackward at 0x7f7119f5a2e8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x, target_x = iters.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 4, 6, 5, 8, 2, 3, 9, 2, 4, 9, 9, 0, 1, 4, 4, 1, 4, 9, 5, 1, 3, 6,\n",
      "        2, 8, 8, 9, 7, 2, 2, 2, 1, 5, 7, 9, 7, 1, 0, 1, 7, 6, 5, 7, 8, 5, 7, 8,\n",
      "        8, 4, 5, 9, 1, 4, 6, 0, 4, 1, 6, 3, 6, 8, 2, 3, 5, 5, 3, 2, 3, 9, 9, 2,\n",
      "        9, 6, 4, 5, 8, 5, 5, 8, 7, 3, 5, 8, 8, 1, 2, 7, 6, 1, 2, 4, 0, 6, 3, 4,\n",
      "        9, 6, 2, 8, 5, 0, 7, 2, 4, 4, 7, 2, 9, 2, 4, 8, 2, 5, 9, 7, 2, 1, 0, 5,\n",
      "        4, 8, 0, 8, 4, 4, 0, 6])\n",
      "torch.Size([128])\n",
      "tensor([[[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [ 2.2815,  2.0489,  1.8744,  ...,  2.2815,  2.3590, -2.4291],\n",
      "          ...,\n",
      "          [ 1.7193,  1.7581,  1.5255,  ..., -1.0334, -0.4324, -2.4291],\n",
      "          [ 1.6612,  1.5642,  1.2928,  ..., -0.8201,  0.2267, -2.4291],\n",
      "          [ 1.8162,  1.5642,  1.1571,  ..., -0.2192,  0.5756, -2.4291]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [ 2.2428,  1.9478,  1.6921,  ...,  2.1051,  2.3215, -2.4183],\n",
      "          ...,\n",
      "          [ 1.6134,  1.6528,  1.3578,  ..., -1.0416, -0.4319, -2.4183],\n",
      "          [ 1.5544,  1.4561,  1.1218,  ..., -0.7859,  0.2761, -2.4183],\n",
      "          [ 1.7708,  1.4954,  1.0234,  ..., -0.1566,  0.6104, -2.4183]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [ 0.7052,  0.6076,  0.4905,  ...,  0.9198,  0.8612, -2.2214],\n",
      "          ...,\n",
      "          [ 0.4320,  0.5491,  0.6076,  ..., -1.0898, -0.8947, -2.2214],\n",
      "          [ 0.3540,  0.3345,  0.3540,  ..., -1.0703, -0.5435, -2.2214],\n",
      "          [ 0.5100,  0.4515,  0.2369,  ..., -0.7581, -0.5045, -2.2214]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291,  1.1765,  1.1184,  ...,  1.1571,  1.3898,  1.3704],\n",
      "          [-2.4291,  1.3704,  1.0408,  ...,  1.4673,  1.6418,  1.5448],\n",
      "          [-2.4291,  1.0214,  0.8858,  ...,  1.2928,  1.5255,  1.4285],\n",
      "          ...,\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "         [[-2.4183,  0.9644,  0.8661,  ...,  0.3548,  0.9054,  1.0628],\n",
      "          [-2.4183,  1.2398,  0.8268,  ...,  0.6891,  1.1414,  1.2004],\n",
      "          [-2.4183,  0.9448,  0.7088,  ...,  0.4138,  0.8661,  0.9644],\n",
      "          ...,\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "         [[-2.2214,  0.3345,  0.1589,  ..., -0.3094,  0.2759,  0.4710],\n",
      "          [-2.2214,  0.6271,  0.1394,  ...,  0.0418,  0.5881,  0.7247],\n",
      "          [-2.2214,  0.3540,  0.0418,  ..., -0.2704,  0.2759,  0.4515],\n",
      "          ...,\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  1.1959,  1.1184,  0.9827],\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  0.3430,  0.2654,  0.3236],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -0.6844, -0.7813, -0.7620]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  1.0038,  0.8858,  0.7088],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  0.3351,  0.2171,  0.2171],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -0.4319, -0.5696, -0.6089]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  0.6661,  0.5686,  0.3930],\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  0.0613, -0.0558, -0.0167],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -0.6411, -0.7581, -0.7776]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  0.1879,  0.0716,  0.0328],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -0.0835, -0.0253, -0.1998],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -0.1029, -0.2773, -0.4324]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  0.1188,  0.0794,  0.1188],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  0.0008,  0.0991, -0.0976],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -0.0582, -0.1959, -0.3532]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -0.7581, -0.8557, -0.8752],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -0.8947, -0.7971, -0.9532],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -0.9142, -0.9922, -1.0898]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-0.3936, -0.3549, -0.1610,  ...,  0.0522,  0.1685,  0.1491],\n",
      "          [-0.8977, -0.3743, -0.0060,  ..., -0.1223,  0.0716,  0.1491],\n",
      "          [-1.3047, -1.4598, -0.6650,  ..., -0.4518, -0.1416,  0.0910]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [ 1.8495,  2.1051,  1.9478,  ...,  0.0204, -0.0976, -0.1762],\n",
      "          [ 0.3744,  1.4168,  1.8691,  ...,  0.1581, -0.0779, -0.1762],\n",
      "          [-0.9236, -0.4319,  0.7481,  ...,  0.3744,  0.0401, -0.1172]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [ 2.5196,  2.6367,  2.4221,  ...,  0.1198,  0.0223, -0.0167],\n",
      "          [ 0.8417,  2.0123,  2.6172,  ...,  0.4320,  0.1003,  0.0028],\n",
      "          [-0.7386, -0.1923,  1.0954,  ...,  0.9003,  0.3540,  0.0808]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [ 1.4091,  0.4399,  1.1765,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [ 0.4011, -0.2773,  1.2153,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-0.6263,  0.6725,  2.0876,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [ 0.8858, -0.3532,  0.0204,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-0.1172, -0.9236,  0.2368,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-1.1399,  0.0794,  1.1218,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [ 0.7052, -0.5630, -0.3484,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-0.2118, -0.9922,  0.0418,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-1.1678,  0.0028,  0.9393,  ..., -2.2214, -2.2214, -2.2214]]]])\n"
     ]
    }
   ],
   "source": [
    "print(target_x)\n",
    "print(target_x.size())\n",
    "input_x.size()\n",
    "print(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_x = conv1(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResBlockLayer(nn.Module):\n",
    "    def __init__(self, block, planes, num_blocks, stride, in_planes=None):\n",
    "        super(ResBlockLayer, self).__init__()\n",
    "        if in_planes is not None:\n",
    "            self.in_planes = in_planes\n",
    "        else:\n",
    "            self.in_planes = 64\n",
    "        print(\"str:\" + str(self.in_planes))\n",
    "        self.layer = self._make_layer(block, planes, num_blocks, stride)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out\n",
    "\n",
    "    def get_in_plances(self):\n",
    "        return self.in_planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str:64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1 = ResBlockLayer(BasicBlock, 64, 2, 1)\n",
    "out1 = block1(output_x)\n",
    "out1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "str:64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 16, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_p = block1.get_in_plances()\n",
    "print(in_p)\n",
    "block2 = ResBlockLayer(BasicBlock, 128, 2, 2, in_p)\n",
    "out2 = block2(out1)\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "str:128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256, 8, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_p = block2.get_in_plances()\n",
    "print(in_p)\n",
    "block3 = ResBlockLayer(BasicBlock, 256, 2, 2, in_p)\n",
    "out3 = block3(out2)\n",
    "out3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "str:256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_p = block3.get_in_plances()\n",
    "print(in_p)\n",
    "block4 = ResBlockLayer(BasicBlock, 512, 2, 2, in_p)\n",
    "out4 = block4(out3)\n",
    "out4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResOutputLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_classes=10):\n",
    "        super(ResOutputLayer, self).__init__()\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.avg_pool2d(x, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_layer = ResOutputLayer(BasicBlock)\n",
    "result = out_layer(out4)\n",
    "result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_tensor = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3060])\n"
     ]
    }
   ],
   "source": [
    "print(fl_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "long_tensor = fl_tensor.long()\n",
    "print(long_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
